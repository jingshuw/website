%% This BibTeX bibliography file was created using BibDesk.
%% https://bibdesk.sourceforge.io/

%% Created for xinranli at 2021-01-03 17:10:47 -0600 


%% Saved with string encoding Unicode (UTF-8) 



@article{Du:2020aa,
	Author = {Du, Jin-Hong and Gao, Ming and Wang, Jingshu},
	Date = {2020/12/31},
	Doi = {10.1101/2020.12.26.424452},
	Journal = {bioRxiv},
	Month = {01},
	N2 = {Trajectory inference methods analyze thousands of cells from single-cell sequencing technologies and computationally infer their developmental trajectories. Though many tools have been developed for trajectory inference, most of them lack a coherent statistical model and reliable uncertainty quantification. In this paper, we present VITAE, a probabilistic method combining a latent hierarchical mixture model with variational autoencoders to infer trajectories from posterior approximations. VITAE is computationally scalable and can adjust for confounding covariates to integrate multiple datasets. We show that VITAE outperforms other state-of-the-art trajectory inference methods on both real and synthetic data under various trajectory topologies. We also apply VITAE to jointly analyze two single-cell RNA sequencing datasets on mouse neocortex. Our results suggest that VITAE can successfully uncover a shared developmental trajectory of the projection neurons and reliably order cells from both datasets along the inferred trajectory.Competing Interest StatementThe authors have declared no competing interest.},
	Pages = {2020.12.26.424452},
	Title = {Model-based Trajectory Inference for Single-Cell RNA Sequencing Using Deep Learning with a Mixture Prior},
	Ty = {JOUR},
	Url = {http://biorxiv.org/content/early/2020/12/27/2020.12.26.424452.abstract},
	Year = {2020},
	Bdsk-Url-1 = {http://biorxiv.org/content/early/2020/12/27/2020.12.26.424452.abstract},
	Bdsk-Url-2 = {https://doi.org/10.1101/2020.12.26.424452}}

@article{Wang:2020aa,
	Author = {Wang, Jingshu and Zhao, Qingyuan and Bowden, Jack and Hemani, Gilbran and Smith, George Davey and Small, Dylan S. and Zhang, Nancy R.},
	Date = {2020/11/11},
	Doi = {10.1101/2020.05.06.077982},
	Journal = {bioRxiv},
	Month = {01},
	N2 = {Over a decade of genome-wide association studies have led to the finding that significant genetic associations tend to be spread across the genome for complex traits, leading to the recent proposal of an ``omnigenic''model where almost all genes contribute to every complex trait. Such an omnigenic phenomenon complicates Mendelian Randomization studies, where natural genetic variations are used as instruments to infer the causal effect of heritable risk factors. We reexamine the assumptions of existing Mendelian Randomization methods and show how they need to be revised to allow for pervasive pleiotropy and heterogeneous effect sizes. We propose a comprehensive framework GRAPPLE (Genome-wide mR Analysis under Pervasive PLEiotropy) to analyze the causal effect of a target risk factor with heterogeneous genetic instruments and identify possible pleiotropic patterns from data. By using summary statistics from genome-wide association studies, GRAPPLE can efficiently use both strong and weak genetic instruments, detect the existence of multiple pleiotropic pathways, adjust for confounding risk factors, and determine the causal direction. With GRAPPLE, we analyze the effect of blood lipids, body mass index, and systolic blood pressure on 25 disease outcomes, gaining new information on their causal relationships and the potential pleiotropic pathways.Competing Interest StatementThe authors have declared no competing interest.},
	Pages = {2020.05.06.077982},
	Title = {Causal Inference for Heritable Phenotypic Risk Factors Using Heterogeneous Genetic Instruments},
	Ty = {JOUR},
	Url = {http://biorxiv.org/content/early/2020/05/08/2020.05.06.077982.abstract},
	Year = {2020},
	Bdsk-Url-1 = {http://biorxiv.org/content/early/2020/05/08/2020.05.06.077982.abstract},
	Bdsk-Url-2 = {https://doi.org/10.1101/2020.05.06.077982}}

@misc{wang2020detecting,
	Archiveprefix = {arXiv},
	Author = {Jingshu Wang and Lin Gui and Weijie J. Su and Chiara Sabatti and Art B. Owen},
	Date = {2020/06/06},
	Eprint = {1610.03330},
	Primaryclass = {stat.ME},
	Title = {Detecting Multiple Replicating Signals using Adaptive Filtering Procedures},
	Year = {2020}}

@article{Zhou:2020aa,
	Abstract = {While single cell RNA sequencing (scRNA-seq) is invaluable for studying cell populations, cell-surface proteins are often integral markers of cellular function and serve as primary targets for therapeutic intervention. Here we propose a transfer learning framework, single cell Transcriptome to Protein prediction with deep neural network (cTP-net), to impute surface protein abundances from scRNA-seq data by learning from existing single-cell multi-omic resources.},
	Author = {Zhou, Zilu and Ye, Chengzhong and Wang, Jingshu and Zhang, Nancy R.},
	Date = {2020/01/31},
	Date-Added = {2021-01-03 17:05:55 -0600},
	Date-Modified = {2021-01-03 17:05:55 -0600},
	Doi = {10.1038/s41467-020-14391-0},
	Id = {Zhou2020},
	Isbn = {2041-1723},
	Journal = {Nature Communications},
	Number = {1},
	Pages = {651},
	Title = {Surface protein imputation from single cell transcriptomes by deep neural networks},
	Ty = {JOUR},
	Url = {https://doi.org/10.1038/s41467-020-14391-0},
	Volume = {11},
	Year = {2020},
	Bdsk-Url-1 = {https://doi.org/10.1038/s41467-020-14391-0}}

@article{Agarwal:2020aa,
	Abstract = {Single cell sequencing technologies are transforming biomedical research. However, due to the inherent nature of the data, single cell RNA sequencing analysis poses new computational and statistical challenges. We begin with a survey of a selection of topics in this field, with a gentle introduction to the biology and a more detailed exploration of the technical noise. We consider in detail the problem of single cell data denoising, sometimes referred to as "imputation" in the relevant literature. We discuss why this is not a typical statistical imputation problem, and review current approaches to this problem. We then explore why the use of denoised values in downstream analyses invites novel statistical insights, and how denoising uncertainty should be accounted for to yield valid statistical inference. The utilization of denoised or imputed matrices in statistical inference is not unique to single cell genomics, and arises in many other fields. We describe the challenges in this type of analysis, discuss some preliminary solutions, and highlight unresolved issues.},
	Author = {Agarwal, Divyansh and Wang, Jingshu and Zhang, Nancy R.},
	Date = {2020/02},
	Date-Added = {2021-01-03 17:05:33 -0600},
	Date-Modified = {2021-01-03 17:05:33 -0600},
	Doi = {10.1214/19-STS7560},
	Isbn = {0883-4237},
	Journal = {Statist. Sci.},
	Keywords = {Single cell biology; RNA sequencing; imputation; post-denoising inference; empirical Bayes; deep learning},
	La = {en},
	Number = {1},
	Pages = {112--128},
	Publisher = {The Institute of Mathematical Statistics},
	Title = {Data Denoising and Post-Denoising Corrections in Single Cell RNA Sequencing},
	Ty = {JOUR},
	Url = {https://projecteuclid.org:443/euclid.ss/1583226032},
	Volume = {35},
	Year = {2020},
	Bdsk-Url-1 = {https://projecteuclid.org:443/euclid.ss/1583226032},
	Bdsk-Url-2 = {https://doi.org/10.1214/19-STS7560}}

@article{Wang:2019ab,
	Abstract = {Single-cell RNA sequencing (scRNA-seq) data are noisy and sparse. Here, we show that transfer learning across datasets remarkably improves data quality. By coupling a deep autoencoder with a Bayesian model, SAVER-X extracts transferable geneâˆ’gene relationships across data from different labs, varying conditions and divergent species, to denoise new target datasets.},
	Author = {Wang, Jingshu and Agarwal, Divyansh and Huang, Mo and Hu, Gang and Zhou, Zilu and Ye, Chengzhong and Zhang, Nancy R.},
	Date = {2019/09/01},
	Date-Added = {2021-01-03 17:03:47 -0600},
	Date-Modified = {2021-01-03 17:03:47 -0600},
	Doi = {10.1038/s41592-019-0537-1},
	Id = {Wang2019},
	Isbn = {1548-7105},
	Journal = {Nature Methods},
	Number = {9},
	Pages = {875--878},
	Title = {Data denoising with transfer learning in single-cell transcriptomics},
	Ty = {JOUR},
	Url = {https://doi.org/10.1038/s41592-019-0537-1},
	Volume = {16},
	Year = {2019},
	Bdsk-Url-1 = {https://doi.org/10.1038/s41592-019-0537-1}}

@article{Zhao:2019ab,
	Abstract = {Summary-data Mendelian randomization (MR) has become a popular research design to estimate the causal effect of risk exposures. With the sample size of GWAS continuing to increase, it is now possible to use genetic instruments that are only weakly associated with the exposure.We propose a three-sample genome-wide design where typically 1000 independent genetic instruments across the whole genome are used. We develop an empirical partially Bayes statistical analysis approach where instruments are weighted according to their strength; thus weak instruments bring less variation to the estimator. The estimator is highly efficient with many weak genetic instruments and is robust to balanced and/or sparse pleiotropy.We apply our method to estimate the causal effect of body mass index (BMI) and major blood lipids on cardiovascular disease outcomes, and obtain substantially shorter confidence intervals (CIs). In particular, the estimated causal odds ratio of BMI on ischaemic stroke is 1.19 (95{\%} CI: 1.07--1.32, P-value {$<$}0.001); the estimated causal odds ratio of high-density lipoprotein cholesterol (HDL-C) on coronary artery disease (CAD) is 0.78 (95{\%} CI: 0.73--0.84, P-value {$<$}0.001). However, the estimated effect of HDL-C attenuates and become statistically non-significant when we only use strong instruments.A genome-wide design can greatly improve the statistical power of MR studies. Robust statistical methods may alleviate but not solve the problem of horizontal pleiotropy. Our empirical results suggest that the relationship between HDL-C and CAD is heterogeneous, and it may be too soon to completely dismiss the HDL hypothesis.},
	Author = {Zhao, Qingyuan and Chen, Yang and Wang, Jingshu and Small, Dylan S},
	Date-Added = {2021-01-03 17:03:00 -0600},
	Date-Modified = {2021-01-03 17:03:00 -0600},
	Doi = {10.1093/ije/dyz142},
	Isbn = {0300-5771},
	Journal = {International Journal of Epidemiology},
	Journal1 = {Int J Epidemiol},
	Month = {1/3/2021},
	Number = {5},
	Pages = {1478--1492},
	Title = {Powerful three-sample genome-wide design and robust statistical inference in summary-data Mendelian randomization},
	Ty = {JOUR},
	Url = {https://doi.org/10.1093/ije/dyz142},
	Volume = {48},
	Year = {2019},
	Year1 = {2019/10/01},
	Bdsk-Url-1 = {https://doi.org/10.1093/ije/dyz142}}

@article{Zhao:2020aa,
	Abstract = {Mendelian randomization (MR) is a method of exploiting genetic variation to unbiasedly estimate a causal effect in presence of unmeasured confounding. MR is being widely used in epidemiology and other related areas of population science. In this paper, we study statistical inference in the increasingly popular two-sample summary-data MR design. We show a linear model for the observed associations approximately holds in a wide variety of settings when all the genetic variants satisfy the exclusion restriction assumption, or in genetic terms, when there is no pleiotropy. In this scenario, we derive a maximum profile likelihood estimator with provable consistency and asymptotic normality. However, through analyzing real datasets, we find strong evidence of both systematic and idiosyncratic pleiotropy in MR, echoing the omnigenic model of complex traits that is recently proposed in genetics. We model the systematic pleiotropy by a random effects model, where no genetic variant satisfies the exclusion restriction condition exactly. In this case, we propose a consistent and asymptotically normal estimator by adjusting the profile score. We then tackle the idiosyncratic pleiotropy by robustifying the adjusted profile score. We demonstrate the robustness and efficiency of the proposed methods using several simulated and real datasets.},
	Author = {Zhao, Qingyuan and Wang, Jingshu and Hemani, Gibran and Bowden, Jack and Small, Dylan S.},
	Date = {2020/06},
	Date-Added = {2021-01-03 17:01:57 -0600},
	Date-Modified = {2021-01-03 17:01:57 -0600},
	Doi = {10.1214/19-AOS1866},
	Isbn = {0090-5364},
	Journal = {Ann. Statist.},
	Keywords = {Causal inference; limited information maximum likelihood; weak instruments; errors in variables; path analysis; pleiotropy effects},
	La = {en},
	Number = {3},
	Pages = {1742--1769},
	Publisher = {The Institute of Mathematical Statistics},
	Title = {Statistical inference in two-sample summary-data Mendelian randomization using robust adjusted profile score},
	Ty = {JOUR},
	Url = {https://projecteuclid.org:443/euclid.aos/1594972837},
	Volume = {48},
	Year = {2020},
	Bdsk-Url-1 = {https://projecteuclid.org:443/euclid.aos/1594972837},
	Bdsk-Url-2 = {https://doi.org/10.1214/19-AOS1866}}

@article{Zhao:2019aa,
	Abstract = {Instrumental variable analysis is a widely used method to estimate causal effects in the presence of unmeasured confounding. When the instruments, exposure and outcome are not measured in the same sample, Angrist and Krueger (J. Amer. Statist. Assoc. 87 (1992) 328-336) suggested to use two-sample instrumental variable (TSIV) estimators that use sample moments from an instrument-exposure sample and an instrument-outcome sample. However, this method is biased if the two samples are from heterogeneous populations so that the distributions of the instruments are different. In linear structural equation models, we derive a new class of TSIV estimators that are robust to heterogeneous samples under the key assumption that the structural relations in the two samples are the same. The widely used two-sample two-stage least squares estimator belongs to this class. It is generally not asymptotically efficient, although we find that it performs similarly to the optimal TSIV estimator in most practical situations. We then attempt to relax the linearity assumption. We find that, unlike one-sample analyses, the TSIV estimator is not robust to misspecified exposure model. Additionally, to nonparametrically identify the magnitude of the causal effect, the noise in the exposure must have the same distributions in the two samples. However, this assumption is in general untestable because the exposure is not observed in one sample. Nonetheless, we may still identify the sign of the causal effect in the absence of homogeneity of the noise.},
	Author = {Zhao, Qingyuan and Wang, Jingshu and Spiller, Wes and Bowden, Jack and Small, Dylan S.},
	Date = {2019/05},
	Date-Added = {2021-01-03 17:01:31 -0600},
	Date-Modified = {2021-01-03 17:01:31 -0600},
	Doi = {10.1214/18-STS692},
	Isbn = {0883-4237},
	Journal = {Statist. Sci.},
	Keywords = {Generalized method of moments; linkage disequilibrium; local average treatment effect; Mendelian randomization; two stage least squares},
	La = {en},
	Number = {2},
	Pages = {317--333},
	Publisher = {The Institute of Mathematical Statistics},
	Title = {Two-Sample Instrumental Variable Analyses Using Heterogeneous Samples},
	Ty = {JOUR},
	Url = {https://projecteuclid.org:443/euclid.ss/1563501644},
	Volume = {34},
	Year = {2019},
	Bdsk-Url-1 = {https://projecteuclid.org:443/euclid.ss/1563501644},
	Bdsk-Url-2 = {https://doi.org/10.1214/18-STS692}}

@article{Wang:2019aa,
	Abstract = {ABSTRACTMeta-analysis combines results from multiple studies aiming to increase power in finding their common effect. It would typically reject the null hypothesis of no effect if any one of the studies shows strong significance. The partial conjunction null hypothesis is rejected only when at least r of n component hypotheses are nonnull with r = 1 corresponding to a usual meta-analysis. Compared with meta-analysis, it can encourage replicable findings across studies. A by-product of it when applied to different r values is a confidence interval of r quantifying the proportion of nonnull studies. Benjamini and Heller (2008) provided a valid test for the partial conjunction null by ignoring the r ? 1 smallest p-values and applying a valid meta-analysis p-value to the remaining n ? r + 1 p-values. We provide sufficient and necessary conditions of admissible combined p-value for the partial conjunction hypothesis among monotone tests. Non-monotone tests always dominate monotone tests but are usually too unreasonable to be used in practice. Based on these findings, we propose a generalized form of Benjamini and Heller?s test which allows usage of various types of meta-analysis p-values, and apply our method to an example in assessing replicable benefit of new anticoagulants across subgroups of patients for stroke prevention.},
	Annote = {doi: 10.1080/01621459.2017.1385465},
	Author = {Wang, Jingshu and Owen, Art B.},
	Booktitle = {Journal of the American Statistical Association},
	Date = {2019/01/02},
	Date = {2019/01/02},
	Date-Added = {2021-01-03 17:01:04 -0600},
	Date-Modified = {2021-01-03 17:01:04 -0600},
	Doi = {10.1080/01621459.2017.1385465},
	Isbn = {0162-1459},
	Journal = {Journal of the American Statistical Association},
	Journal1 = {null},
	M3 = {doi: 10.1080/01621459.2017.1385465},
	Month = {01},
	Number = {525},
	Pages = {158--168},
	Publisher = {Taylor \& Francis},
	Title = {Admissibility in Partial Conjunction Testing},
	Ty = {JOUR},
	Url = {https://doi.org/10.1080/01621459.2017.1385465},
	Volume = {114},
	Year = {2019},
	Year1 = {2019},
	Bdsk-Url-1 = {https://doi.org/10.1080/01621459.2017.1385465}}

@article{Wang:2018aa,
	Author = {Wang, Jingshu and Huang, Mo and Torre, Eduardo and Dueck, Hannah and Shaffer, Sydney and Murray, John and Raj, Arjun and Li, Mingyao and Zhang, Nancy R.},
	Date = {2018/07/10},
	Date-Added = {2021-01-03 17:00:15 -0600},
	Date-Modified = {2021-01-03 17:00:15 -0600},
	Doi = {10.1073/pnas.1721085115},
	Journal = {Proceedings of the National Academy of Sciences},
	Journal1 = {Proc Natl Acad Sci USA},
	Lp = {E6446},
	Month = {07},
	N2 = {We developed deconvolution of single-cell expression distribution (DESCEND), a method to recover cross-cell distribution of the true gene expression level from observed counts in single-cell RNA sequencing, allowing adjustment of known confounding cell-level factors. With the recovered distribution, DESCEND provides reliable estimates of distribution-based measurements, such as the dispersion of true gene expression and the probability that true gene expression is positive. This is important, as with better estimates of these measurements, DESCEND clarifies and improves many downstream analyses including finding differentially expressed genes, identifying cell types, and selecting differentiation markers. Another contribution is that we verified using nine public datasets a simple ``Poisson-alpha''noise model for the technical noise of unique molecular identifier-based single-cell RNA-sequencing data, clarifying the current intense debate on this issue.Single-cell RNA sequencing (scRNA-seq) enables the quantification of each gene's expression distribution across cells, thus allowing the assessment of the dispersion, nonzero fraction, and other aspects of its distribution beyond the mean. These statistical characterizations of the gene expression distribution are critical for understanding expression variation and for selecting marker genes for population heterogeneity. However, scRNA-seq data are noisy, with each cell typically sequenced at low coverage, thus making it difficult to infer properties of the gene expression distribution from raw counts. Based on a reexamination of nine public datasets, we propose a simple technical noise model for scRNA-seq data with unique molecular identifiers (UMI). We develop deconvolution of single-cell expression distribution (DESCEND), a method that deconvolves the true cross-cell gene expression distribution from observed scRNA-seq counts, leading to improved estimates of properties of the distribution such as dispersion and nonzero fraction. DESCEND can adjust for cell-level covariates such as cell size, cell cycle, and batch effects. DESCEND's noise model and estimation accuracy are further evaluated through comparisons to RNA FISH data, through data splitting and simulations and through its effectiveness in removing known batch effects. We demonstrate how DESCEND can clarify and improve downstream analyses such as finding differentially expressed genes, identifying cell types, and selecting differentiation markers.},
	Number = {28},
	Pages = {E6437},
	Title = {Gene expression distribution deconvolution in single-cell RNA sequencing},
	Ty = {JOUR},
	Url = {http://www.pnas.org/content/115/28/E6437.abstract},
	Volume = {115},
	Year = {2018},
	Bdsk-Url-1 = {http://www.pnas.org/content/115/28/E6437.abstract},
	Bdsk-Url-2 = {https://doi.org/10.1073/pnas.1721085115}}

@article{Huang:2018aa,
	Abstract = {In single-cell RNA sequencing (scRNA-seq) studies, only a small fraction of the transcripts present in each cell are sequenced. This leads to unreliable quantification of genes with low or moderate expression, which hinders downstream analysis. To address this challenge, we developed SAVER (single-cell analysis via expression recovery), an expression recovery method for unique molecule index (UMI)-based scRNA-seq data that borrows information across genes and cells to provide accurate expression estimates for all genes.},
	Author = {Huang, Mo and Wang, Jingshu and Torre, Eduardo and Dueck, Hannah and Shaffer, Sydney and Bonasio, Roberto and Murray, John I. and Raj, Arjun and Li, Mingyao and Zhang, Nancy R.},
	Date = {2018/07/01},
	Date-Added = {2021-01-03 16:59:21 -0600},
	Date-Modified = {2021-01-03 16:59:21 -0600},
	Doi = {10.1038/s41592-018-0033-z},
	Id = {Huang2018},
	Isbn = {1548-7105},
	Journal = {Nature Methods},
	Number = {7},
	Pages = {539--542},
	Title = {SAVER: gene expression recovery for single-cell RNA sequencing},
	Ty = {JOUR},
	Url = {https://doi.org/10.1038/s41592-018-0033-z},
	Volume = {15},
	Year = {2018},
	Bdsk-Url-1 = {https://doi.org/10.1038/s41592-018-0033-z}}

@article{Wang:2017aa,
	Abstract = {We consider large-scale studies in which thousands of significance tests are performed simultaneously. In some of these studies, the multiple testing procedure can be severely biased by latent confounding factors such as batch effects and unmeasured covariates that correlate with both primary variable(s) of interest (e.g., treatment variable, phenotype) and the outcome. Over the past decade, many statistical methods have been proposed to adjust for the confounders in hypothesis testing. We unify these methods in the same framework, generalize them to include multiple primary variables and multiple nuisance variables, and analyze their statistical properties. In particular, we provide theoretical guarantees for RUV-4 [Gagnon-Bartsch, Jacob and Speed (2013)] and LEAPP [Ann. Appl. Stat. 6 (2012) 1664-1688], which correspond to two different identification conditions in the framework: the first requires a set of "negative controls" that are known a priori to follow the null distribution; the second requires the true nonnulls to be sparse. Two different estimators which are based on RUV-4 and LEAPP are then applied to these two scenarios. We show that if the confounding factors are strong, the resulting estimators can be asymptotically as powerful as the oracle estimator which observes the latent confounding factors. For hypothesis testing, we show the asymptotic $z$-tests based on the estimators can control the type I error. Numerical experiments show that the false discovery rate is also controlled by the Benjamini-Hochberg procedure when the sample size is reasonably large.},
	Author = {Wang, Jingshu and Zhao, Qingyuan and Hastie, Trevor and Owen, Art B.},
	Date = {2017/10},
	Date-Added = {2021-01-03 16:58:10 -0600},
	Date-Modified = {2021-01-03 16:58:10 -0600},
	Doi = {10.1214/16-AOS1511},
	Isbn = {0090-5364},
	Journal = {Ann. Statist.},
	Keywords = {Empirical null; surrogate variable analysis; unwanted variation; batch effect; robust regression},
	La = {en},
	Number = {5},
	Pages = {1863--1894},
	Publisher = {The Institute of Mathematical Statistics},
	Title = {Confounder adjustment in multiple hypothesis testing},
	Ty = {JOUR},
	Url = {https://projecteuclid.org:443/euclid.aos/1509436821},
	Volume = {45},
	Year = {2017},
	Bdsk-Url-1 = {https://projecteuclid.org:443/euclid.aos/1509436821},
	Bdsk-Url-2 = {https://doi.org/10.1214/16-AOS1511}}

@article{Owen:2016aa,
	Abstract = {Factor analysis is over a century old, but it is still problematic to choose the number of factors for a given data set. We provide a systematic review of current methods and then introduce a method based on bi-cross-validation, using randomly held-out submatrices of the data to choose the optimal number of factors. We find it performs better than many existing methods especially when both the number of variables and the sample size are large and some of the factors are relatively weak. Our performance criterion is based on recovery of an underlying signal, equal to the product of the usual factor and loading matrices. Like previous comparisons, our work is simulation based. Recent advances in random matrix theory provide principled choices for the number of factors when the noise is homoscedastic, but not for the heteroscedastic case. The simulations we chose are designed using guidance from random matrix theory. In particular, we include factors which are asymptotically too small to detect, factors large enough to detect but not large enough to improve the estimate, and two classes of factors (weak and strong) large enough to be useful. We also find that a form of early stopping regularization improves the recovery of the signal matrix.},
	Author = {Owen, Art B. and Wang, Jingshu},
	Date = {2016/02},
	Date-Added = {2021-01-03 16:56:35 -0600},
	Date-Modified = {2021-01-03 16:56:35 -0600},
	Doi = {10.1214/15-STS539},
	Isbn = {0883-4237},
	Journal = {Statist. Sci.},
	Keywords = {Parallel analysis; random matrix theory; scree plot; unwanted variation},
	La = {en},
	Number = {1},
	Pages = {119--139},
	Publisher = {The Institute of Mathematical Statistics},
	Title = {Bi-Cross-Validation for Factor Analysis},
	Ty = {JOUR},
	Url = {https://projecteuclid.org:443/euclid.ss/1455115917},
	Volume = {31},
	Year = {2016},
	Bdsk-Url-1 = {https://projecteuclid.org:443/euclid.ss/1455115917},
	Bdsk-Url-2 = {https://doi.org/10.1214/15-STS539}}

@incollection{kang2020online,
  title={Online Single-cell RNA-seq Data Denoising with Transfer Learning},
  author={Kang, Bowei and Abeysinghe, Eroma and Agarwal, Divyansh and Wang, Quanli and Pamidighantam, Sudhakar and Huang, Mo and Zhang, Nancy R and Wang, Jingshu},
  booktitle={Practice and Experience in Advanced Research Computing},
  pages={469--472},
  year={2020}
}
